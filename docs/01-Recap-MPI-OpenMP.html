<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="CSC Training">
  <title>Recap: MPI &amp; OpenMP</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://mlouhivu.github.io/static-engine/reveal/3.5.0/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" href="theme/csc-2016/csc.css" id="theme">
  <link rel="stylesheet" href="theme/csc-2016/fonts.css">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'theme/csc-2016/pdf.css' : 'https://mlouhivu.github.io/static-engine/reveal/3.5.0/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="https://mlouhivu.github.io/static-engine/reveal/3.5.0/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section class="slide level1 title-slide" data-background-size="contain" data-background="theme/csc-2016/img/title-en.png">
  <h1>Recap: MPI &amp; OpenMP</h1>
  <p>CSC Training, 2019-02</p>
</section>

<section id="processes-and-threads" class="slide level1" data-background-size="contain">
<h1>Processes and threads</h1>
<figure>
<img src="img/processes-threads.png" />
</figure>
<div class="column">
<h2 id="process">Process</h2>
<ul>
<li>Independent execution units</li>
<li>Have their own state information and <em>own memory</em> address space</li>
</ul>
</div>
<div class="column">
<h2 id="thread">Thread</h2>
<ul>
<li>A single process may contain multiple threads</li>
<li>Have their own state information, but <em>share</em> the <em>same memory</em> address space</li>
</ul>
</div>
</section>
<section id="processes-and-threads-1" class="slide level1" data-background-size="contain">
<h1>Processes and threads</h1>
<figure>
<img src="img/processes-threads.png" />
</figure>
<div class="column">
<h2 id="process-1">Process</h2>
<ul>
<li>Long-lived: spawned when parallel program started, killed when program is finished</li>
<li>Explicit communication between processes</li>
</ul>
</div>
<div class="column">
<h2 id="thread-1">Thread</h2>
<ul>
<li>Short-lived: created when entering a parallel region, destroyed (joined) when region ends</li>
<li>Communication through shared memory</li>
</ul>
</div>
</section>
<section id="openmp-walkthrough" class="slide level1 section-slide" data-background-size="contain" data-background="theme/default/img/section.png">
<h1>OpenMP walkthrough</h1>
</section>
<section id="three-components-of-openmp" class="slide level1" data-background-size="contain">
<h1>Three components of OpenMP</h1>
<ul>
<li>Compiler directives and constructs
<ul>
<li>Expresses shared memory parallelization</li>
<li>Preceded by sentinel, can compile serial version</li>
</ul></li>
<li>Runtime library routines
<ul>
<li>Small number of library functions</li>
<li>Can be discarded in serial version via conditional compiling</li>
</ul></li>
<li>Environment variables
<ul>
<li>Specify the number of threads, etc.</li>
</ul></li>
</ul>
</section>
<section id="openmp-directives" class="slide level1" data-background-size="contain">
<h1>OpenMP directives</h1>
<ul>
<li>Sentinels precede each OpenMP directive</li>
<li>C/C++: <code>#pragma omp</code></li>
<li><p>Fortran free form: <code>!$omp</code></p></li>
<li>Compilers that support OpenMP usually require an option (flag) that enables the feature
<ul>
<li>Without an enabling flag the OpenMP sentinels are treated as comments and a serial version will be compiled</li>
</ul></li>
</ul>
</section>
<section id="parallel-construct" class="slide level1" data-background-size="contain">
<h1>Parallel construct</h1>
<div class="column">
<ul>
<li>Defines a <em>parallel region</em>
<ul>
<li>Prior to it only one thread, master</li>
<li>Creates a team of threads: master+slave threads</li>
<li>At end of the block is a barrier and all shared data is synchronized</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode fortran"><code class="sourceCode fortran"><span class="co">!$omp parallel</span>

<span class="co">!$omp end parallel</span></code></pre></div>
</div>
<div class="column">
<figure>
<img src="img/omp-parallel.png" />
</figure>
</div>
</section>
<section id="example-helloworld-with-openmp" class="slide level1" data-background-size="contain">
<h1>Example: Helloworld with OpenMP</h1>
<div class="column">
<div class="sourceCode"><pre class="sourceCode fortran"><code class="sourceCode fortran"><span class="kw">program</span> hello
<span class="kw">use</span> omp_lib

<span class="dt">integer</span> <span class="dt">::</span> omp_rank

<span class="co">!$omp parallel private(omp_rank)</span>
omp_rank <span class="kw">=</span> omp_get_thread_num()
<span class="fu">print</span> <span class="kw">*</span>, <span class="st">&#39;Hello world! by &amp; thread &#39;</span>, omp_rank
<span class="co">!$omp end parallel</span>


<span class="kw">end program</span> hello</code></pre></div>
</div>
<div class="column">
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;omp.h&gt;</span>

<span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span> argv[]) {
  <span class="dt">int</span> omp_rank;

  <span class="pp">#pragma omp parallel private(omp_rank)</span>
  {
  omp_rank = omp_get_thread_num();
  printf(<span class="st">&quot;Hello world! by thread %d&quot;</span>, omp_rank);
  }
}</code></pre></div>
</div>
</section>
<section id="example-helloworld-with-openmp-1" class="slide level1" data-background-size="contain">
<h1>Example: Helloworld with OpenMP</h1>
<div class="column">
<pre class="console"><code>&gt; ftn omp_hello.f90 -o omp
&gt; aprun -e OMP_NUM_THREADS=4 -n 1 -d 4 ./omp

Hello world! by thread 0
Hello world! by thread 2
Hello world! by thread 1
Hello world! by thread 3</code></pre>
</div>
<div class="column">
<pre class="console"><code>&gt; cc omp_hello.c -o omp
&gt; aprun -e OMP_NUM_THREADS=4 -n 1 -d 4 ./omp

Hello world! by thread 2
Hello world! by thread 3
Hello world! by thread 0
Hello world! by thread 1</code></pre>
</div>
</section>
<section id="how-do-the-threads-interact" class="slide level1" data-background-size="contain">
<h1>How do the threads interact?</h1>
<ul>
<li>Because of the shared address space threads can &quot;communicate&quot; using <em>shared</em> variables</li>
<li>Threads often need some <em>private</em> work space together with shared variables
<ul>
<li>For example the index variable of a loop</li>
</ul></li>
<li>Visibility of different variables is defined using <em>data-sharing clauses</em> in the parallel region definition
<ul>
<li><code>private</code>, <code>firstprivate</code>, <code>lastprivate</code>, <code>shared</code>, <code>default</code></li>
<li>Local variables defined in the parallel region, or functions called within it are private</li>
</ul></li>
</ul>
</section>
<section id="work-sharing" class="slide level1" data-background-size="contain">
<h1>Work sharing</h1>
<ul>
<li>Parallel region creates an &quot;Single Program Multiple Data&quot; instance where each thread executes the same code</li>
<li>How can one split the work between the threads of a parallel region?
<ul>
<li>Loop construct</li>
<li>Single/Master construct</li>
<li>Sections</li>
<li>Task construct</li>
</ul></li>
</ul>
</section>
<section id="loop-constructs" class="slide level1" data-background-size="contain">
<h1>Loop constructs</h1>
<ul>
<li>Directive instructing compiler to share the work of a loop
<ul>
<li>Fortran: <code>$OMP DO</code></li>
<li>C/C++: <code>#pragma omp for</code></li>
<li>Directive must be inside a parallel region</li>
<li>Can also be combined with parallel:
<ul>
<li><code>$OMP PARALLEL DO</code></li>
<li><code>#pragma omp parallel for</code></li>
</ul></li>
</ul></li>
<li>Loop index is private by default</li>
<li>Work sharing can be controlled using <em>schedule</em> clause
<ul>
<li><code>static</code>, <code>dynamic</code>, <code>guided</code>, or <code>runtime</code></li>
</ul></li>
</ul>
</section>
<section id="reduction-clause" class="slide level1" data-background-size="contain">
<h1>Reduction clause</h1>
<dl>
<dt><code>reduction(operator:var_list)</code></dt>
<dd><p>Performs reduction on the (scalar) variables in list (sum, max, min, ...)</p>
<ul>
<li>Private reduction variable is created for each thread's partial result</li>
<li>Private reduction variable is initialized to operator's initial value, e.g., 0 for sum</li>
<li>After parallel region the reduction operation is applied to private variables and <strong>result is aggregated to the shared variable</strong></li>
</ul>
</dd>
</dl>
</section>
<section id="execution-controls" class="slide level1" data-background-size="contain">
<h1>Execution controls</h1>
<ul>
<li>Sometimes a part of parallel region should be executed only by the master thread or by a single thread at time
<ul>
<li>I/O, initializations, updating global values, etc.</li>
<li>Remember the synchronization!</li>
</ul></li>
<li>OpenMP provides clauses for controlling the execution of code blocks
<ul>
<li><code>barrier</code></li>
<li><code>master</code> &amp; <code>single</code></li>
<li><code>critical</code></li>
</ul></li>
</ul>
</section>
<section id="openmp-summary" class="slide level1" data-background-size="contain">
<h1>OpenMP summary</h1>
<figure>
<img src="img/omp-summary.png" />
</figure>
</section>
<section id="getting-started-with-mpi" class="slide level1 section-slide" data-background-size="contain" data-background="theme/default/img/section.png">
<h1>Getting started with MPI</h1>
</section>
<section id="message-passing-interface" class="slide level1" data-background-size="contain">
<h1>Message-passing interface</h1>
<ul>
<li>MPI is an application programming interface (API) for communication between separate processes
<ul>
<li>The most popular <em>distributed</em> parallel computing method</li>
<li>MPI programs are portable and scalable</li>
</ul></li>
<li>MPI is flexible and comprehensive
<ul>
<li>Several communication methods and patterns</li>
<li>Parallel IO</li>
</ul></li>
<li>MPI standardization by MPI Forum
<ul>
<li>Latest version is 3.1, version 1.0 in 1994</li>
</ul></li>
</ul>
</section>
<section id="execution-model-in-mpi" class="slide level1" data-background-size="contain">
<h1>Execution model in MPI</h1>
<ul>
<li>Parallel program is launched as set of <em>independent</em>, <em>identical processes</em>
<ul>
<li>The same program code and instructions</li>
</ul></li>
<li>MPI runtime assigns each process a <em>rank</em>
<ul>
<li>identification of the processes</li>
<li>Processes can perform different tasks and handle different data basing on their rank</li>
<li>Can reside in different nodes</li>
</ul></li>
<li>The way to launch parallel program is implementation dependent</li>
</ul>
</section>
<section id="communication" class="slide level1" data-background-size="contain">
<h1>Communication</h1>
<div class="column">
<ul>
<li>Data is local to the MPI processes
<ul>
<li>they need to <em>communicate</em> to coordinate work</li>
</ul></li>
<li>Point-to-point communication
<ul>
<li>Messages are sent between two processes</li>
</ul></li>
<li>Collective communication
<ul>
<li>Involving a number of processes at the same time</li>
</ul></li>
</ul>
</div>
<div class="column">
<figure>
<img src="img/communication-schematic.png" />
</figure>
</div>
</section>
<section id="mpi-point-to-point-operations" class="slide level1" data-background-size="contain">
<h1>MPI point-to-point operations</h1>
<ul>
<li>One process <em>sends</em> a message to another process that <em>receives</em> it with <code>MPI_Send</code> and <code>MPI_Recv</code> routines</li>
<li>Sends and receives in a program should match â€“ one receive per send</li>
<li>Each message (envelope) contains
<ul>
<li>The actual <em>data</em> that is to be sent</li>
<li>The <em>datatype</em> of each element of data</li>
<li>The <em>number of elements</em> the data consists of</li>
<li>An identification number for the message (<em>tag</em>)</li>
<li>The ranks of the <em>source</em> and <em>destination</em> process</li>
</ul></li>
</ul>
</section>
<section id="non-blocking-communication" class="slide level1" data-background-size="contain">
<h1>Non-blocking communication</h1>
<ul>
<li>Non-blocking communication is usually the smarter way to do point-to-point communication in MPI
<ul>
<li>Enables some computing concurrently with communication</li>
<li>Avoids many common dead-lock situations</li>
</ul></li>
<li>Non-blocking communication realization
<ul>
<li><code>MPI_Isend</code></li>
<li><code>MPI_Irecv</code></li>
<li><code>MPI_Wait</code> / <code>MPI_Waitall</code></li>
</ul></li>
</ul>
</section>
<section id="collective-operations-examples" class="slide level1" data-background-size="contain">
<h1>Collective operations examples</h1>
<figure>
<img src="img/collective-patterns.png" />
</figure>
</section>
<section id="mpi-datatypes" class="slide level1" data-background-size="contain">
<h1>MPI datatypes</h1>
<ul>
<li>MPI has a number of predefined datatypes to represent data</li>
<li>Each C or Fortran datatype has a corresponding MPI datatype
<ul>
<li>C examples: <code>MPI_INT</code> for <code>int</code> and <code>MPI_DOUBLE</code> for <code>double</code></li>
<li>Fortran example: <code>MPI_INTEGER</code> for <code>integer</code></li>
</ul></li>
<li>One can also define custom datatypes</li>
</ul>
</section>
<section id="communicators" class="slide level1" data-background-size="contain">
<h1>Communicators</h1>
<figure>
<img src="img/communicators.png" />
</figure>
</section>
<section id="basic-mpi-summary" class="slide level1" data-background-size="contain">
<h1>Basic MPI summary</h1>
<figure>
<img src="img/mpi-summary.png" />
</figure>
</section>
    </div>
  </div>

  <script src="https://mlouhivu.github.io/static-engine/reveal/3.5.0/lib/js/head.min.js"></script>
  <script src="https://mlouhivu.github.io/static-engine/reveal/3.5.0/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: false,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: false,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'none', // none/fade/slide/convex/concave/zoom
        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,
        height: 1080,

        // Optional reveal.js plugins
        dependencies: [
          { src: 'https://mlouhivu.github.io/static-engine/reveal/3.5.0/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'https://mlouhivu.github.io/static-engine/reveal/3.5.0/plugin/zoom-js/zoom.js', async: true },
          { src: 'https://mlouhivu.github.io/static-engine/reveal/3.5.0/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
